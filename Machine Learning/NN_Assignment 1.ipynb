{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 1NN for Iris Dataset and Test Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the euclidean distance\n",
    "def predi(test_sample,x_train):\n",
    "    n_distances = []\n",
    "    for train_sample in x_train:\n",
    "        distance = 0\n",
    "        for i in range(len(test_sample)):\n",
    "            distance += (train_sample[i] - test_sample[i])**2\n",
    "        n_distances.append(np.sqrt(distance))\n",
    "    return n_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find the minimum\n",
    "def minimum(n_distances):\n",
    "    min_val = n_distances[0]\n",
    "    min_ind = 0\n",
    "    for i in range(len(n_distances)):\n",
    "        if n_distances[i] < min_val:\n",
    "            min_val = n_distances[i]\n",
    "            min_ind = i\n",
    "    return min_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to find the 1 nearest neighbor\n",
    "def nn(x_train,x_test,y_train,y_test):\n",
    "    import numpy as np\n",
    "    y_pred = []\n",
    "    for test_sample in x_test:\n",
    "        dist = predi(test_sample,x_train)\n",
    "        min_index = minimum(dist)\n",
    "        y_pred.append(y_train[min_index])\n",
    "    error_rate = np.mean(y_pred != y_test)\n",
    "    print(\"The test error rate for the dataset is :\",error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train ,y_test = train_test_split(iris['data'],iris['target'],random_state=236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4)\n",
      "[[5.6 2.8 4.9 2. ]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [5.  3.  1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [7.2 3.  5.8 1.6]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 4)\n",
      "[[6.9 3.1 5.4 2.1]\n",
      " [6.  2.2 4.  1. ]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.4 2.7 5.3 1.9]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error rate for the dataset is : 0.02631578947368421\n"
     ]
    }
   ],
   "source": [
    "nn(X_train , X_test , y_train ,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 1NN for Ionosphere Dataset and Test Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Xj = np.genfromtxt(\"ionosphere.txt\",delimiter = \",\",usecols = np.arange(34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.     ,  0.     ,  0.99539, -0.05889,  0.85243,  0.02306,\n",
       "         0.83398, -0.37708,  1.     ,  0.0376 ,  0.85243, -0.17755,\n",
       "         0.59755, -0.44945,  0.60536, -0.38223,  0.84356, -0.38542,\n",
       "         0.58212, -0.32192,  0.56971, -0.29674,  0.36946, -0.47357,\n",
       "         0.56811, -0.51171,  0.41078, -0.46168,  0.21266, -0.3409 ,\n",
       "         0.42267, -0.54487,  0.18641, -0.453  ],\n",
       "       [ 1.     ,  0.     ,  1.     , -0.18829,  0.93035, -0.36156,\n",
       "        -0.10868, -0.93597,  1.     , -0.04549,  0.50874, -0.67743,\n",
       "         0.34432, -0.69707, -0.51685, -0.97515,  0.05499, -0.62237,\n",
       "         0.33109, -1.     , -0.13151, -0.453  , -0.18056, -0.35734,\n",
       "        -0.20332, -0.26569, -0.20468, -0.18401, -0.1904 , -0.11593,\n",
       "        -0.16626, -0.06288, -0.13738, -0.02447],\n",
       "       [ 1.     ,  0.     ,  1.     , -0.03365,  1.     ,  0.00485,\n",
       "         1.     , -0.12062,  0.88965,  0.01198,  0.73082,  0.05346,\n",
       "         0.85443,  0.00827,  0.54591,  0.00299,  0.83775, -0.13644,\n",
       "         0.75535, -0.0854 ,  0.70887, -0.27502,  0.43385, -0.12062,\n",
       "         0.57528, -0.4022 ,  0.58984, -0.22145,  0.431  , -0.17365,\n",
       "         0.60436, -0.2418 ,  0.56045, -0.38238]])"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xj[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "yj = np.genfromtxt(\"ionosphere.txt\",delimiter = \",\", usecols = 34 , dtype = 'int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yj[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xj_train,xj_test,Yj_train,Yj_test = train_test_split(Xj,yj,random_state = 236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error rate for the dataset is : 0.1590909090909091\n"
     ]
    }
   ],
   "source": [
    "nn(xj_train,xj_test,Yj_train,Yj_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 3NN for Iris Dataset and Test Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(row1,row2):\n",
    "    distancess = 0\n",
    "    for i in range(len(row1)):\n",
    "        distancess += (row1[i]-row2[i])**2\n",
    "    return(np.sqrt(distancess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classify(x_train,y_train,x_input,n_neighbors=3):\n",
    "    labels = []\n",
    "    for i in x_input:\n",
    "        nn_distance = []\n",
    "        for j in range(len(x_train)):\n",
    "            dis = euclidean(np.array(x_train[j,:]),i)\n",
    "            nn_distance.append(dis)\n",
    "        distancess = np.argsort(nn_distance)[:3]\n",
    "        labelss = y_train[distancess]\n",
    "        label = mode(labelss)\n",
    "        label = label.mode[0]\n",
    "        labels.append(label)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train ,y_test = train_test_split(iris['data'],iris['target'],random_state=236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_classify(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error rate is : 0.02631578947368421\n"
     ]
    }
   ],
   "source": [
    "error_rate = np.mean(y_pred!=y_test)\n",
    "print(\"The test error rate is :\",error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 3NN for Ionosphere Dataset and Test Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "XK = np.genfromtxt(\"ionosphere.txt\",delimiter = \",\",usecols = np.arange(34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "yK = np.genfromtxt(\"ionosphere.txt\",delimiter = \",\", usecols = 34 , dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xk_train,xk_test,Yk_train,Yk_test = train_test_split(XK,yK,random_state = 236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = predict_classify(xk_train,Yk_train,xk_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error rate is : 0.125\n"
     ]
    }
   ],
   "source": [
    "error_rate = np.mean(y_predicted != Yk_test)\n",
    "print(\"The test error rate is :\",error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Interesting observations of the Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pandas gives a better understanding of the dataset and how it is constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the CSV file\n",
    "iris = pd.read_csv(\"iris_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallength</th>\n",
       "      <th>sepalwidth</th>\n",
       "      <th>petallength</th>\n",
       "      <th>petalwidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepallength  sepalwidth  petallength  petalwidth        class\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head() #Printing the top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.shape #There are 150 features and 5 columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   sepallength  150 non-null    float64\n",
      " 1   sepalwidth   150 non-null    float64\n",
      " 2   petallength  150 non-null    float64\n",
      " 3   petalwidth   150 non-null    float64\n",
      " 4   class        150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 1 column has categorical data and all other columns are of non numerics types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallength</th>\n",
       "      <th>sepalwidth</th>\n",
       "      <th>petallength</th>\n",
       "      <th>petalwidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepallength  sepalwidth  petallength  petalwidth\n",
       "count   150.000000  150.000000   150.000000  150.000000\n",
       "mean      5.843333    3.054000     3.758667    1.198667\n",
       "std       0.828066    0.433594     1.764420    0.763161\n",
       "min       4.300000    2.000000     1.000000    0.100000\n",
       "25%       5.100000    2.800000     1.600000    0.300000\n",
       "50%       5.800000    3.000000     4.350000    1.300000\n",
       "75%       6.400000    3.300000     5.100000    1.800000\n",
       "max       7.900000    4.400000     6.900000    2.500000"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the count of each column along with their mean , standard deviation , minimum and maximum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepallength    0\n",
       "sepalwidth     0\n",
       "petallength    0\n",
       "petalwidth     0\n",
       "class          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isnull() is used to check if there are any missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Implementation of KNN for a general value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(row1,row2):\n",
    "    distancess = 0\n",
    "    for i in range(len(row1)):\n",
    "        distancess += (row1[i]-row2[i])**2\n",
    "    return(np.sqrt(distancess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classi(x_train,y_train,x_input,n_neighbors):\n",
    "    labels = []\n",
    "    for i in x_input:\n",
    "        nn_distance = []\n",
    "        for j in range(len(x_train)):\n",
    "            dis = euclidean(np.array(x_train[j,:]),i)\n",
    "            nn_distance.append(dis)\n",
    "        distancess = np.argsort(nn_distance)[:n_neighbors]\n",
    "        labelss = y_train[distancess]\n",
    "        label = mode(labelss)\n",
    "        label = label.mode[0]\n",
    "        labels.append(label)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xc_train,xc_test,yc_train,yc_test = train_test_split(iris['data'],iris['target'],random_state = 236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predic = predict_classi(xc_train,yc_train,xc_test,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Test Error rate is : 0.07894736842105263\n"
     ]
    }
   ],
   "source": [
    "error_rate = np.mean(y_predic != yc_test)\n",
    "print(\"The Test Error rate is :\",error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above test error rate is for k = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error rate is : 0.02631578947368421\n"
     ]
    }
   ],
   "source": [
    "y_predic = predict_classi(xc_train,yc_train,xc_test,11)\n",
    "error_rate1 = np.mean(y_predic != yc_test)\n",
    "print(\"The test error rate is :\",error_rate1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above Test error rate is for k = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Generalized KNN for Ionosphere Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "XC = np.genfromtxt(\"ionosphere.txt\",delimiter = \",\",usecols = np.arange(34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "yC = np.genfromtxt(\"ionosphere.txt\",delimiter = \",\", usecols = 34 , dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xC_train,xC_test,YC_train,YC_test = train_test_split(XC,yC,random_state = 236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = predict_classi(xC_train,YC_train,xC_test,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error rate is : 0.13636363636363635\n"
     ]
    }
   ],
   "source": [
    "error_rate = np.mean(y_pre != YC_test)\n",
    "print(\"The test error rate is :\",error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Test Error Rate shown above is for k = 11 for the ionosphere Dataset. Similarly the test error for any value of k can be depicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error rate is : 0.14772727272727273\n"
     ]
    }
   ],
   "source": [
    "y_pre = predict_classi(xC_train,YC_train,xC_test,9)\n",
    "error_rate = np.mean(y_pre != YC_test)\n",
    "print(\"The test error rate is :\",error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above test error rate displayed is for k = 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN for Generalized value of K has been implemented and tested for both the Datasets as shown above. Also, the error rate is displayed for different values of K."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
